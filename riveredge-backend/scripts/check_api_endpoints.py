#!/usr/bin/env python3
"""
æ£€æŸ¥å¹¶è§„èŒƒ API ç«¯ç‚¹å‘½å
ç¡®ä¿æ‰€æœ‰ç«¯ç‚¹éµå¾ª RESTful è§„èŒƒå’Œæ–°çš„å‘½åè§„èŒƒ
"""

import re
from pathlib import Path
from typing import List, Dict, Tuple

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent.parent
BACKEND_SRC = PROJECT_ROOT / "riveredge-backend" / "src"

# API ç«¯ç‚¹å‘½åè§„èŒƒ
ENDPOINT_RULES = {
    "prefix": {
        "platform": ["/tenants", "/packages", "/admin", "/auth", "/monitoring", "/saved-searches"],
        "core": ["/users", "/roles", "/permissions", "/departments", "/positions", 
                "/data-dictionaries", "/system-parameters", "/code-rules", "/custom-fields",
                "/site-settings", "/invitation-codes", "/languages", "/applications", "/menus",
                "/integration-configs", "/files", "/apis", "/data-sources", "/datasets",
                "/message-configs", "/message-templates", "/messages", "/scheduled-tasks",
                "/approval-processes", "/approval-instances", "/electronic-records", "/scripts",
                "/print-templates", "/print-devices", "/operation-logs", "/login-logs",
                "/online-users", "/data-backups", "/help-documents"],
        "personal": ["/user-profile", "/user-preferences", "/user-messages", "/user-tasks"]
    },
    "patterns": {
        "kebab-case": r"^[a-z]+(-[a-z]+)*$",  # kebab-case æ ¼å¼
        "plural": True,  # åº”è¯¥ä½¿ç”¨å¤æ•°å½¢å¼
    }
}


def check_endpoint_naming(file_path: Path) -> List[Dict]:
    """æ£€æŸ¥å•ä¸ªæ–‡ä»¶çš„ç«¯ç‚¹å‘½å"""
    issues = []
    
    try:
        content = file_path.read_text(encoding='utf-8')
        
        # æŸ¥æ‰¾ APIRouter å®šä¹‰
        router_match = re.search(r'router\s*=\s*APIRouter\([^)]*\)', content, re.MULTILINE)
        if router_match:
            router_def = router_match.group(0)
            
            # æå– prefix
            prefix_match = re.search(r'prefix=["\']([^"\']+)["\']', router_def)
            if prefix_match:
                prefix = prefix_match.group(1)
                
                # æ£€æŸ¥ prefix æ ¼å¼
                if not re.match(ENDPOINT_RULES["patterns"]["kebab-case"], prefix.lstrip('/')):
                    issues.append({
                        "file": str(file_path.relative_to(BACKEND_SRC)),
                        "type": "prefix_format",
                        "issue": f"å‰ç¼€ '{prefix}' ä¸ç¬¦åˆ kebab-case è§„èŒƒ",
                        "prefix": prefix
                    })
                
                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å¤æ•°å½¢å¼ï¼ˆç®€å•æ£€æŸ¥ï¼‰
                if prefix and not prefix.endswith('s') and prefix not in ['/auth', '/admin', '/monitoring']:
                    # æŸäº›å•è¯æœ¬èº«å°±æ˜¯å¤æ•°æˆ–ç‰¹æ®Šå½¢å¼ï¼Œéœ€è¦æ’é™¤
                    singular_words = ['user', 'role', 'permission', 'department', 'position', 
                                   'menu', 'file', 'api', 'message', 'script', 'help']
                    if any(prefix.endswith(f'/{word}') for word in singular_words):
                        issues.append({
                            "file": str(file_path.relative_to(BACKEND_SRC)),
                            "type": "prefix_plural",
                            "issue": f"å‰ç¼€ '{prefix}' åº”è¯¥ä½¿ç”¨å¤æ•°å½¢å¼",
                            "prefix": prefix
                        })
        
        # æŸ¥æ‰¾è·¯ç”±è£…é¥°å™¨
        route_patterns = [
            r'@router\.(get|post|put|delete|patch)\(["\']([^"\']+)["\']',
            r'@router\.(get|post|put|delete|patch)\(([^,)]+)',
        ]
        
        for pattern in route_patterns:
            for match in re.finditer(pattern, content):
                route_path = match.group(2).strip('"\'')
                # æ¸…ç†è·¯å¾„ï¼ˆç§»é™¤å˜é‡éƒ¨åˆ†ï¼‰
                route_path = re.sub(r'\{[^}]+\}', '', route_path)
                
                if route_path and route_path != '/':
                    # æ£€æŸ¥è·¯å¾„æ ¼å¼
                    path_parts = [p for p in route_path.split('/') if p]
                    for part in path_parts:
                        if part and not re.match(ENDPOINT_RULES["patterns"]["kebab-case"], part):
                            issues.append({
                                "file": str(file_path.relative_to(BACKEND_SRC)),
                                "type": "route_path_format",
                                "issue": f"è·¯å¾„éƒ¨åˆ† '{part}' ä¸ç¬¦åˆ kebab-case è§„èŒƒ",
                                "path": route_path
                            })
    
    except Exception as e:
        issues.append({
            "file": str(file_path.relative_to(BACKEND_SRC)),
            "type": "error",
            "issue": f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}",
        })
    
    return issues


def scan_all_api_files() -> Tuple[List[Dict], Dict[str, List[str]]]:
    """æ‰«ææ‰€æœ‰ API æ–‡ä»¶"""
    all_issues = []
    endpoint_map = {
        "platform": [],
        "core": [],
        "personal": [],
        "other": []
    }
    
    # æ‰«æ platform API
    platform_api_dir = BACKEND_SRC / "platform" / "api"
    if platform_api_dir.exists():
        for api_file in platform_api_dir.rglob("*.py"):
            if api_file.name != "__init__.py" and not api_file.name.startswith("_"):
                issues = check_endpoint_naming(api_file)
                all_issues.extend(issues)
                
                # æå–ç«¯ç‚¹ä¿¡æ¯
                try:
                    content = api_file.read_text(encoding='utf-8')
                    prefix_match = re.search(r'prefix=["\']([^"\']+)["\']', content)
                    if prefix_match:
                        endpoint_map["platform"].append(prefix_match.group(1))
                except:
                    pass
    
    # æ‰«æ core API
    core_api_dir = BACKEND_SRC / "core" / "api"
    if core_api_dir.exists():
        for api_file in core_api_dir.rglob("*.py"):
            if api_file.name != "__init__.py" and not api_file.name.startswith("_"):
                issues = check_endpoint_naming(api_file)
                all_issues.extend(issues)
                
                # æå–ç«¯ç‚¹ä¿¡æ¯
                try:
                    content = api_file.read_text(encoding='utf-8')
                    prefix_match = re.search(r'prefix=["\']([^"\']+)["\']', content)
                    if prefix_match:
                        prefix = prefix_match.group(1)
                        if prefix.startswith("/user-"):
                            endpoint_map["personal"].append(prefix)
                        else:
                            endpoint_map["core"].append(prefix)
                except:
                    pass
    
    return all_issues, endpoint_map


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ” æ£€æŸ¥ API ç«¯ç‚¹å‘½åè§„èŒƒ")
    print("=" * 60)
    
    issues, endpoint_map = scan_all_api_files()
    
    # æ˜¾ç¤ºç«¯ç‚¹æ˜ å°„
    print("\nğŸ“‹ API ç«¯ç‚¹åˆ†ç±»:")
    print(f"\nå¹³å°çº§ç«¯ç‚¹ ({len(endpoint_map['platform'])}):")
    for ep in sorted(set(endpoint_map['platform'])):
        print(f"  - {ep}")
    
    print(f"\nç³»ç»Ÿçº§ç«¯ç‚¹ ({len(endpoint_map['core'])}):")
    for ep in sorted(set(endpoint_map['core'])):
        print(f"  - {ep}")
    
    print(f"\nä¸ªäººåŠŸèƒ½ç«¯ç‚¹ ({len(endpoint_map['personal'])}):")
    for ep in sorted(set(endpoint_map['personal'])):
        print(f"  - {ep}")
    
    # æ˜¾ç¤ºé—®é¢˜
    if issues:
        print(f"\nâš ï¸  å‘ç° {len(issues)} ä¸ªé—®é¢˜:")
        for issue in issues:
            print(f"\n  ğŸ“ {issue['file']}")
            print(f"     âŒ {issue['issue']}")
    else:
        print("\nâœ… æ‰€æœ‰ API ç«¯ç‚¹å‘½åç¬¦åˆè§„èŒƒï¼")
    
    print("\n" + "=" * 60)
    
    return issues, endpoint_map


if __name__ == '__main__':
    main()

