"""
æ•°æ®åº“è¿ç§»çŠ¶æ€æ£€æµ‹è„šæœ¬

æ£€æŸ¥å½“å‰é¡¹ç›®çš„è¿ç§»æ–‡ä»¶çŠ¶æ€ï¼ŒåŒ…æ‹¬ï¼š
1. è¿ç§»æ–‡ä»¶åˆ—è¡¨å’Œé¡ºåº
2. è¿ç§»æ–‡ä»¶æ ¼å¼æ£€æŸ¥
3. ç‰ˆæœ¬å·è¿ç»­æ€§æ£€æŸ¥
4. è¿ç§»æ–‡ä»¶å‘½åè§„èŒƒæ£€æŸ¥

Author: Auto (AI Assistant)
Date: 2025-01-01
"""

import re
import sys
from pathlib import Path
from typing import List, Dict, Tuple
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

MIGRATIONS_DIR = Path(__file__).parent / "models"


def get_migration_files() -> List[Path]:
    """è·å–æ‰€æœ‰è¿ç§»æ–‡ä»¶"""
    files = []
    for file in MIGRATIONS_DIR.glob("*.py"):
        if file.name != "__init__.py":
            files.append(file)
    return sorted(files)


def parse_migration_name(filename: str) -> Tuple[int, str, str]:
    """
    è§£æè¿ç§»æ–‡ä»¶å
    
    æ ¼å¼: {version}_{timestamp}_{name}.py
    ä¾‹å¦‚: 0_init_schema.py æˆ– 1_20251230192227_create_kuaizhizao_tables.py
    
    Returns:
        (version, timestamp, name)
    """
    # ç§»é™¤ .py æ‰©å±•å
    name = filename.replace(".py", "")
    
    # åŒ¹é…æ ¼å¼: version_timestamp_name æˆ– version_name
    match = re.match(r"^(\d+)(?:_(\d+))?_(.+)$", name)
    if match:
        version = int(match.group(1))
        timestamp = match.group(2) or ""
        name_part = match.group(3)
        return (version, timestamp, name_part)
    
    # å¦‚æœæ ¼å¼ä¸åŒ¹é…ï¼Œå°è¯•åªæå–ç‰ˆæœ¬å·
    match = re.match(r"^(\d+)", name)
    if match:
        version = int(match.group(1))
        return (version, "", name)
    
    return (999, "", name)


def check_migration_format(file_path: Path) -> Dict[str, any]:
    """æ£€æŸ¥è¿ç§»æ–‡ä»¶æ ¼å¼"""
    issues = []
    content = file_path.read_text(encoding="utf-8")
    
    # æ£€æŸ¥å¿…è¦çš„å¯¼å…¥
    if "from tortoise import BaseDBAsyncClient" not in content:
        issues.append("ç¼ºå°‘å¿…è¦çš„å¯¼å…¥: from tortoise import BaseDBAsyncClient")
    
    # æ£€æŸ¥ upgrade å‡½æ•°
    if "async def upgrade" not in content:
        issues.append("ç¼ºå°‘ upgrade å‡½æ•°")
    elif "async def upgrade(db: BaseDBAsyncClient) -> str:" not in content:
        issues.append("upgrade å‡½æ•°ç­¾åä¸æ­£ç¡®")
    
    # æ£€æŸ¥ RUN_IN_TRANSACTION
    if "RUN_IN_TRANSACTION" not in content:
        issues.append("ç¼ºå°‘ RUN_IN_TRANSACTION å˜é‡")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ SQL è¯­å¥
    if "return \"\"\"" in content or 'return """' in content:
        # æ£€æŸ¥ SQL æ˜¯å¦ä¸ºç©º
        sql_match = re.search(r'return\s+"""(.*?)"""', content, re.DOTALL)
        if sql_match and not sql_match.group(1).strip():
            issues.append("upgrade å‡½æ•°è¿”å›çš„ SQL ä¸ºç©º")
    
    return {
        "file": file_path.name,
        "valid": len(issues) == 0,
        "issues": issues
    }


def check_version_continuity(migration_files: List[Path]) -> Dict[str, any]:
    """æ£€æŸ¥ç‰ˆæœ¬å·è¿ç»­æ€§"""
    versions = []
    duplicates = []
    
    for file in migration_files:
        version, _, _ = parse_migration_name(file.name)
        if version in versions:
            duplicates.append((version, file.name))
        versions.append(version)
    
    # æ£€æŸ¥è¿ç»­æ€§
    missing = []
    if versions:
        min_version = min(versions)
        max_version = max(versions)
        expected = set(range(min_version, max_version + 1))
        actual = set(versions)
        missing = sorted(expected - actual)
    
    return {
        "versions": sorted(set(versions)),
        "duplicates": duplicates,
        "missing": missing,
        "continuous": len(missing) == 0 and len(duplicates) == 0
    }


def generate_report() -> str:
    """ç”Ÿæˆè¿ç§»çŠ¶æ€æŠ¥å‘Š"""
    migration_files = get_migration_files()
    
    report = []
    report.append("=" * 80)
    report.append("æ•°æ®åº“è¿ç§»çŠ¶æ€æ£€æµ‹æŠ¥å‘Š")
    report.append("=" * 80)
    report.append(f"æ£€æµ‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append(f"è¿ç§»æ–‡ä»¶ç›®å½•: {MIGRATIONS_DIR}")
    report.append("")
    
    # 1. è¿ç§»æ–‡ä»¶åˆ—è¡¨
    report.append("ğŸ“‹ è¿ç§»æ–‡ä»¶åˆ—è¡¨")
    report.append("-" * 80)
    if not migration_files:
        report.append("âŒ æœªæ‰¾åˆ°è¿ç§»æ–‡ä»¶")
    else:
        report.append(f"âœ… æ‰¾åˆ° {len(migration_files)} ä¸ªè¿ç§»æ–‡ä»¶:")
        report.append("")
        for i, file in enumerate(migration_files, 1):
            version, timestamp, name = parse_migration_name(file.name)
            size = file.stat().st_size
            report.append(f"  {i:2d}. [{version:2d}] {file.name}")
            report.append(f"      ç‰ˆæœ¬: {version}, æ—¶é—´æˆ³: {timestamp or 'N/A'}, åç§°: {name}")
            report.append(f"      å¤§å°: {size:,} å­—èŠ‚")
            report.append("")
    
    # 2. ç‰ˆæœ¬å·è¿ç»­æ€§æ£€æŸ¥
    report.append("ğŸ”¢ ç‰ˆæœ¬å·è¿ç»­æ€§æ£€æŸ¥")
    report.append("-" * 80)
    continuity = check_version_continuity(migration_files)
    if continuity["continuous"]:
        report.append("âœ… ç‰ˆæœ¬å·è¿ç»­ï¼Œæ— é‡å¤")
    else:
        if continuity["duplicates"]:
            report.append("âš ï¸  å‘ç°é‡å¤çš„ç‰ˆæœ¬å·:")
            for version, filename in continuity["duplicates"]:
                report.append(f"   ç‰ˆæœ¬ {version}: {filename}")
        if continuity["missing"]:
            report.append("âš ï¸  å‘ç°ç¼ºå¤±çš„ç‰ˆæœ¬å·:")
            report.append(f"   {continuity['missing']}")
    report.append("")
    
    # 3. è¿ç§»æ–‡ä»¶æ ¼å¼æ£€æŸ¥
    report.append("ğŸ“ è¿ç§»æ–‡ä»¶æ ¼å¼æ£€æŸ¥")
    report.append("-" * 80)
    format_issues = []
    for file in migration_files:
        result = check_migration_format(file)
        if not result["valid"]:
            format_issues.append(result)
    
    if not format_issues:
        report.append("âœ… æ‰€æœ‰è¿ç§»æ–‡ä»¶æ ¼å¼æ­£ç¡®")
    else:
        report.append(f"âš ï¸  å‘ç° {len(format_issues)} ä¸ªæ ¼å¼é—®é¢˜:")
        for issue in format_issues:
            report.append(f"   {issue['file']}:")
            for problem in issue["issues"]:
                report.append(f"     - {problem}")
    report.append("")
    
    # 4. è¿ç§»æ–‡ä»¶å‘½åè§„èŒƒæ£€æŸ¥
    report.append("ğŸ“› è¿ç§»æ–‡ä»¶å‘½åè§„èŒƒæ£€æŸ¥")
    report.append("-" * 80)
    naming_issues = []
    for file in migration_files:
        version, timestamp, name = parse_migration_name(file.name)
        issues = []
        
        # æ£€æŸ¥å‘½åæ ¼å¼
        if not re.match(r"^\d+(_\d+)?_.+\.py$", file.name):
            issues.append(f"å‘½åæ ¼å¼ä¸ç¬¦åˆè§„èŒƒ: {file.name}")
        
        # æ£€æŸ¥ç‰ˆæœ¬å·
        if version < 0:
            issues.append(f"ç‰ˆæœ¬å·æ— æ•ˆ: {version}")
        
        # æ£€æŸ¥æ—¶é—´æˆ³æ ¼å¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if timestamp and not re.match(r"^\d{14}$", timestamp):
            issues.append(f"æ—¶é—´æˆ³æ ¼å¼ä¸æ­£ç¡®: {timestamp}")
        
        if issues:
            naming_issues.append({"file": file.name, "issues": issues})
    
    if not naming_issues:
        report.append("âœ… æ‰€æœ‰è¿ç§»æ–‡ä»¶å‘½åç¬¦åˆè§„èŒƒ")
    else:
        report.append(f"âš ï¸  å‘ç° {len(naming_issues)} ä¸ªå‘½åé—®é¢˜:")
        for issue in naming_issues:
            report.append(f"   {issue['file']}:")
            for problem in issue["issues"]:
                report.append(f"     - {problem}")
    report.append("")
    
    # 5. æ€»ç»“
    report.append("ğŸ“Š æ€»ç»“")
    report.append("-" * 80)
    total_issues = len(format_issues) + len(naming_issues)
    if continuity["duplicates"]:
        total_issues += len(continuity["duplicates"])
    if continuity["missing"]:
        total_issues += len(continuity["missing"])
    
    if total_issues == 0:
        report.append("âœ… è¿ç§»æ–‡ä»¶çŠ¶æ€è‰¯å¥½ï¼Œæœªå‘ç°é—®é¢˜")
    else:
        report.append(f"âš ï¸  å‘ç° {total_issues} ä¸ªé—®é¢˜éœ€è¦å¤„ç†")
        report.append("")
        report.append("å»ºè®®æ“ä½œ:")
        if continuity["duplicates"]:
            report.append("  1. ä¿®å¤é‡å¤çš„ç‰ˆæœ¬å·ï¼ˆé‡å‘½åæ–‡ä»¶æˆ–åˆå¹¶è¿ç§»ï¼‰")
        if continuity["missing"]:
            report.append("  2. æ£€æŸ¥ç¼ºå¤±çš„ç‰ˆæœ¬å·æ˜¯å¦å¿…è¦")
        if format_issues:
            report.append("  3. ä¿®å¤è¿ç§»æ–‡ä»¶æ ¼å¼é—®é¢˜")
        if naming_issues:
            report.append("  4. ä¿®å¤è¿ç§»æ–‡ä»¶å‘½åé—®é¢˜")
    
    report.append("")
    report.append("=" * 80)
    
    return "\n".join(report)


if __name__ == "__main__":
    try:
        report = generate_report()
        print(report)
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_file = MIGRATIONS_DIR.parent / "migration_status_report.txt"
        report_file.write_text(report, encoding="utf-8")
        print(f"\næŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
    except Exception as e:
        print(f"âŒ æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

